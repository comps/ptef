The suite consists of hiearchical "levels", separated by directory levels
(or virtual/imaginary levels), with each level having one "runner" responsible
for test execution and results reporting. The API between levels is UNIX/POSIX,
so the runners can be implemented in different programming languages and don't
rely on implementation specifics.

Anything outside the API specification is implementation-dependent, ie. if the
API doesn't specify which tests to run (all? based on some config? list?), it's
up to the runner to decide which tests to include.

As symlinks inside the suite are allowed (to runners, to executables, to dirs)
and always dereferenced by the runner logic, one runner binary could be shared
across levels by simply symlinking it from a common directory. Similarly,
runners can be independent with the common code in include/import/source files.
This spec or the API leave this to the implementation.

-----------------

The test hierarchy behaves as if everything is a test; a file or a directory.
It also doesn't differentiate between a test and a child runner, the API is the
same.

When run as a directory, it's up to the runner to recurse further. In this case,
the runner should look for and execute a file inside the directory matching the
argv[0] of the runner, passing it a test path argument with one level removed,
ie.

/a/b/c/d/e

- runner executable 'builder' in 'a' runs with argument 'b/c/d'
- it finds that 'b' is a directory
- it looks for an executable in 'b' called 'builder'
- it runs the executable, passing 'c/d' to it

When the target found is a file and not a directory, it runs the file, passing
any remaining levels left to it as an argument, ie.

/a/b

- runner executable 'builder' in 'a' runs with argument 'b/c/d'
- it finds that 'b' is an executable file
- it runs 'b', passing 'c/d' as an argument to it

If the path ends on an executable file and the argument would be empty,
no argument is passed. For a directory, this would mean calling ie. 'builder'
without arguments, which could ie. tell it to run all tests under its rule.

This allows, in the above /a/b/c/d/e case, to run ie. a single test 'e' using
the full path specification, or all tests in 'c' with /a/b/c, including,
eventually, 'e', which is part of 'c'.

Additionally, passing the path remainder to a file enables us to run imaginary
or "virtual" tests that cannot be represented by a file on a filesystem (like an
LTP runner) as well as passing "parameters" to tests, ie.
  /a/b/permission/devfileperm
  /a/b/permission/dirperm
  /a/b/permission/fileperm
where 'permission' is an executable file (test).

-----------------

/a/b/c/d/e

- suppose you're in 'c' and want to run 'e'
  - to run all setups from the topmost level, you would
      ../../../run d/e
    as runner is smart enough to know where 'run' is and what PWD you're in,
    it builds the full path as /a/b/c/d/e
    - alternatively, an absolute path can be passed to be run from the runner's
      (argv[0]) location, ignoring CWD:
        ../../../run /a/b/c/d/e

- suppose you're in 'c' and want to run 'e', but have already run the setup
  for 'a' and 'b'
  - you would thus run setup for 'c' and any following dirs like
      ./run d/e
    because './run' doesn't know about anything above it, it constructs
    its own setup, recurses and eventually runs 'e', going back and executing
    cleanups, all the way up to 'c' where it stops, so you can re-run it while
    keeping the setup from 'a' and 'b' intact

-----------------

To run more tests while sharing their setup/cleanup, you can specify more
arguments to the runner binary.

The runner can use a guessing logic to strip a common leading path as it
enumerates the arguments until it encounters an argument where the initially
found leading path prefix cannot be found. Then it passes the list of arguments
(enumerated so far) to a sublevel runner, as arguments.
Note that this is an optional optimization, a runner doesn't need to implement
it (in case the runner is ie. a simple C binary), as it only reduces duplicate
setup/cleanup events when running individually-specified tests.

/a/b
/a/d
/x/y/z

- suppose you're in '/' and the user tells you to run:
    /a/b/c{1,2,3} /a/d /x/y
  which the interactive bash expands to commandline arguments:
    /a/b/c1 /a/b/c2 /a/b/c3 /a/d /x/y
  the runner then takes the first path element of the first argument ('a')
  and grabs all following arguments that share the same prefix (4 of them)
  and runs the 'a/runner' binary, passing it the 4 arguments
  - after it finishes, it continues with parsing arguments, takes 'x' as
    the prefix, however as /x/y is the last argument, it simply runs
    'x/runner' and passes the one argument, 'y' to it

  meanwhile, the 'a/runner' binary would iterate over the arguments it got,
    b/c1 b/c2 b/c3 d
  the same way as the original runner in '/' would, passing first 3 arguments
  to 'b/runner' and running 'd/runner' without arguments, etc.

- suppose you're in '/' and the user gives you:
    /a/b/c1 /x/y /a/b/c2
  which the runner could reorder, however it has to honor the order as /a/b/c2
  might depend on something /x/y did, so it runs all 3 separately, that is
  - running 'a/runner' with 'b/c1'
  - running 'x/runner' with 'y'
  - running 'a/runner' with 'b/c2'

- when two tests are specified where one is the subset of the other,
  like /a/b/c and /a/b/c/d, there's no clear solution to it, because either
  - we run only /a/b/c, which runs 'd' amongst other things
  - we run only /a/b/c/d
  - we run both /a/b/c and then /a/b/c/d separately, ignoring common prefix
  however as common-prefix optimization is optional, choice 3 wins because
  without the optimization, both tests would be run separately, which is also
  what the user would naturally expect

-----------------

Result reporting is done by runners to multiple destinations and should be done
by every runner (every recursion level). Only the test path/basename should be
reported/logged, without any arguments passed.

First, realtime reporting is done to the active TTY or /dev/tty, but only if
the process has a valid terminal (ie. on fd 0). This is done in the following
format:
  STATUS /some/test/name with/spaces
  STATUS /another/test/name
where STATUS is one of PASS (retval 0) or FAIL (retval non-0) for a finished
test or RUN for a test that is being started, meaning the log could look like
  RUN /some/test/name with/spaces
  PASS /some/test/name with/spaces
  RUN /another/test/name
  FAIL /another/test/name
but the lines may be interleaved if the tests run in parallel. In that case,
the runner needs to flock() its active tty (ie. fd 0) to get exclusive access
for writing.
Here, the test name in CWD is "spaces" and "name", with the full dirname being
supplied from a parent runner through the TEF_PREFIX var, ie.
  TEF_PREFIX="/some/test/name with"

The status may be colorized or bold/underline/etc. if the terminal supports it.
Also, there may be any number of spaces/tabs between the status and the test
name, however at least one is mandatory.

Second, the runner writes similar output as it wrote to active terminal to its
standard output. It would however use a binary format with nul-separated results
instead of newline separation and include a 'tefresults' header with ASCII
representation of a header version. Additionally, only the base test names would
be included, without a prefix:
  tefresults\01\0RUN spaces\0PASS spaces\0RUN name\0FAIL name\0

If the stdout is connected to current terminal, this output is suppressed.
In C, this can be done with fstat() on ie. fd 0 vs fd 1 and comparing st_ino
and st_dev, which both together uniquely identify a file on the system (incl.
a terminal device).
It's expected that a parent runner would redirect the output to a log file,
as it doesn't differentiate between a child runner vs child test as "everything
is a test".

When running a test, a runner would redirect both stdout and stderr to a file
inside 'logs' directory in the CWD (same as runner binary), creating it if it
doesn't exist. Alternatively, if TEF_LOGS is nonempty, the log path would be
constructed as $TEF_LOGS/$TEF_PREFIX/. The output should go to a file with
identical name as the test (no suffix) inside this 'logs' dir.

Any log file (stdout redirected) would be opened by the runner as O_APPEND,
allowing test re-run output to be accumulated and test runner binary file
to cumulatively collect results for all runs/reruns.
The test/runner cannot rely on stdout being a seekable file, they have to
use it as a write-only stream, writing the binary header on every open.

-----------------

Random Notes:

-----------------

